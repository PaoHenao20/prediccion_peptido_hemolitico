{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c1fec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n",
      "/Users/paola/Documents/UNIR/TFM/prediccion_peptido_hemolitico/src/modules/transform.py:28: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, 'bool'):\n",
      "/Users/paola/Documents/UNIR/TFM/prediccion_peptido_hemolitico/src/modules/transform.py:30: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, 'object'):\n",
      "/Users/paola/Documents/UNIR/TFM/prediccion_peptido_hemolitico/src/modules/transform.py:32: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, 'long'):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from extract import download_file_from_url\n",
    "from transform import annotate_and_save, clean_df, compute_mordred_descriptors, concat_csv_sin_duplicados, get_smiles, df_to_fasta, run_cd_hit, fasta_to_df, compute_sequence_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdfa775",
   "metadata": {},
   "source": [
    "HemoPI2 data - information link: https://webs.iiitd.edu.in/raghava/hemopi2/download.html\n",
    "ToxinPred3 - information link:  https://webs.iiitd.edu.in/raghava/toxinpred3/download.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daae0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_FOLDER = \"data/raw_test\"\n",
    "CURATED_FOLDER = \"data/curated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e772ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_dict =  {\n",
    "    \"HemoPI_train\": \"https://webs.iiitd.edu.in/raghava/hemopi2/download/cross_val_dataset.csv\",\n",
    "    \"HemoPI_test\": \"https://webs.iiitd.edu.in/raghava/hemopi2/download/independent_dataset.csv\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfefca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo descargado correctamente: data/raw_test/HemoPI_train.csv\n",
      "Archivo descargado correctamente: data/raw_test/HemoPI_test.csv\n",
      "Concatenados 50 filas únicas.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   SEQUENCE  50 non-null     object \n",
      " 1   μM        50 non-null     float64\n",
      " 2   label     50 non-null     int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.3+ KB\n",
      "None\n",
      "================================================================\n",
      "Program: CD-HIT, V4.8.1, Apr 07 2021, 02:35:32\n",
      "Command: cd-hit -i data/curated/peptides.fasta -o\n",
      "         data/curated/cd_hit/peptides_nr_100.fasta -c 1.0\n",
      "\n",
      "Started: Mon Jun  9 23:16:01 2025\n",
      "================================================================\n",
      "                            Output                              \n",
      "----------------------------------------------------------------\n",
      "total seq: 49\n",
      "longest and shortest : 37 and 11\n",
      "Total letters: 964\n",
      "Sequences have been sorted\n",
      "\n",
      "Approximated minimal memory consumption:\n",
      "Sequence        : 0M\n",
      "Buffer          : 1 X 10M = 10M\n",
      "Table           : 1 X 65M = 65M\n",
      "Miscellaneous   : 0M\n",
      "Total           : 75M\n",
      "\n",
      "Table limit with the given memory limit:\n",
      "Max number of representatives: 4000000\n",
      "Max number of word counting entries: 90518514\n",
      "\n",
      "comparing sequences from          0  to         49\n",
      "\n",
      "       49  finished         49  clusters\n",
      "\n",
      "Approximated maximum memory consumption: 75M\n",
      "writing new database\n",
      "Error ejecutando CD-HIT con identidad 1.0: Command '['cd-hit', '-i', 'data/curated/peptides.fasta', '-o', 'data/curated/cd_hit/peptides_nr_100.fasta', '-c', '1.0']' returned non-zero exit status 1.\n",
      "\n",
      "Procesando identidad 1.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fatal Error:\n",
      "file opening failed\n",
      "Program halted !!\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/curated/cd_hit/peptides_nr_100.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m fasta_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcd_hit_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(identity\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.fasta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m csv_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCURATED_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/cd_hit_csv/peptides_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(identity\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 44\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mfasta_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfasta_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#Get SMILES and descriptors:\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(identity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Calcular features\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UNIR/TFM/prediccion_peptido_hemolitico/src/modules/transform.py:113\u001b[0m, in \u001b[0;36mfasta_to_df\u001b[0;34m(fasta_path, output_csv)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SeqIO\n\u001b[1;32m    112\u001b[0m sequences \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m \u001b[43mSeqIO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfasta_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfasta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     sequences\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(record\u001b[38;5;241m.\u001b[39mseq))\n\u001b[1;32m    116\u001b[0m df_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEQUENCE\u001b[39m\u001b[38;5;124m\"\u001b[39m: sequences})\n",
      "File \u001b[0;32m~/miniconda3/envs/prediccion_hemolitico/lib/python3.9/site-packages/Bio/SeqIO/__init__.py:626\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(handle, format, alphabet)\u001b[0m\n\u001b[1;32m    624\u001b[0m iterator_generator \u001b[38;5;241m=\u001b[39m _FormatToIterator\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iterator_generator:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01min\u001b[39;00m AlignIO\u001b[38;5;241m.\u001b[39m_FormatToIterator:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# Use Bio.AlignIO to read in the alignments\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (r \u001b[38;5;28;01mfor\u001b[39;00m alignment \u001b[38;5;129;01min\u001b[39;00m AlignIO\u001b[38;5;241m.\u001b[39mparse(handle, \u001b[38;5;28mformat\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m alignment)\n",
      "File \u001b[0;32m~/miniconda3/envs/prediccion_hemolitico/lib/python3.9/site-packages/Bio/SeqIO/FastaIO.py:196\u001b[0m, in \u001b[0;36mFastaIterator.__init__\u001b[0;34m(self, source, alphabet)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alphabet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe alphabet argument is no longer supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFasta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream)\n",
      "File \u001b[0;32m~/miniconda3/envs/prediccion_hemolitico/lib/python3.9/site-packages/Bio/SeqIO/Interfaces.py:81\u001b[0m, in \u001b[0;36mSequenceIterator.__init__\u001b[0;34m(self, source, alphabet, fmt)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, _PathLikeTypes):\n\u001b[1;32m     80\u001b[0m     mode \u001b[38;5;241m=\u001b[39m modes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     value \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/curated/cd_hit/peptides_nr_100.fasta'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Asegúrate de que las carpetas existen\n",
    "os.makedirs(\"data/curated\", exist_ok=True)\n",
    "os.makedirs(\"data/raw\", exist_ok=True) \n",
    "os.makedirs(\"data/curated/cd_hit\", exist_ok=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for file_name, url in url_dict.items():\n",
    "        download_file_from_url(url, f\"{MAIN_FOLDER}/{file_name}.csv\")\n",
    "\n",
    "    all_data_file_name = \"all_data.csv\"\n",
    "\n",
    "    resultado = concat_csv_sin_duplicados(MAIN_FOLDER,\n",
    "                                            pattern=\"*.csv\",\n",
    "                                            output_path=f\"{CURATED_FOLDER}/{all_data_file_name}\")\n",
    "    print(f\"Concatenados {len(resultado)} filas únicas.\")\n",
    "\n",
    "    data_clean_name = \"all_data_clean.csv\"\n",
    "    # clean and save\n",
    "    df_limpio = clean_df(\n",
    "        resultado,\n",
    "        output_csv=f\"{CURATED_FOLDER}/{data_clean_name}\"\n",
    "    )\n",
    "\n",
    "    print(df_limpio.info())\n",
    "    fasta_file_name = \"peptides.fasta\"\n",
    "    fasta_path = f'{CURATED_FOLDER}/{fasta_file_name}'\n",
    "    fasta = df_to_fasta(df_limpio, seq_col='SEQUENCE', output=fasta_path)\n",
    "\n",
    "    # path = f\"{CURATED_FOLDER}\"\n",
    "    cd_hit_prefix = f\"{CURATED_FOLDER}/cd_hit/peptides_nr\"\n",
    "    smile_folder = \"smile_data\"\n",
    "    descriptor_folder= \"descriptors\"\n",
    "    identities = [1.00, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70]\n",
    "\n",
    "    for identity in identities:\n",
    "        run_cd_hit(fasta_path, cd_hit_prefix, identity)\n",
    "\n",
    "        print(f\"\\nProcesando identidad {identity}...\")\n",
    "\n",
    "        fasta_file = f\"{cd_hit_prefix}_{int(identity * 100)}.fasta\"\n",
    "        \n",
    "        csv_output = f\"{CURATED_FOLDER}/cd_hit_csv/peptides_{int(identity * 100)}.csv\"\n",
    "        df = fasta_to_df(fasta_file, csv_output)\n",
    "\n",
    "\n",
    "        #Get SMILES and descriptors:\n",
    "        if int(identity) == 1:\n",
    "            # Calcular features\n",
    "            features_df = compute_sequence_features(df, seq_column='SEQUENCE')\n",
    "            print(features_df.head())\n",
    "            \n",
    "             # 2. Get SMILES \n",
    "            smiles_output = f\"{CURATED_FOLDER}/{smile_folder}/peptides_{int(identity * 100)}_smiles.csv\"\n",
    "            df_smiles = annotate_and_save(df, output_csv=smiles_output)\n",
    "\n",
    "            # 3. Calcular descriptores Mordred\n",
    "            df_desc = compute_mordred_descriptors(df_smiles)\n",
    "\n",
    "            # 4. Guardar descriptores\n",
    "            final_df = pd.concat([df_smiles, df_desc], axis=1)\n",
    "            final_csv = f\"{CURATED_FOLDER}/{descriptor_folder}/peptides_{int(identity * 100)}_descriptors.csv\"\n",
    "            final_df.to_csv(final_csv, index=False)\n",
    "\n",
    "            #Merge descriptors + sequence-based frequencies\n",
    "            merge_all = final_df.merge(features_df, how='inner', on='SEQUENCE' )\n",
    "            final_path = f\"{CURATED_FOLDER}/descriptors_and_frequencies/peptides_{int(identity * 100)}.csv\"\n",
    "            merge_all.to_csv(final_path, index=False)\n",
    "\n",
    "            print(f\"✅ saved {final_path}\")\n",
    "            df_100 = merge_all\n",
    "            print(df_100.info())\n",
    "        \n",
    "        else:\n",
    "            # obtener smile y descriptores y de sequence-based frequencies los otras identidades:\n",
    "            merge_df = df.merge(df_100, how='left' , on='SEQUENCE' )\n",
    "            print(df.info())\n",
    "            final_csv = f\"{CURATED_FOLDER}/descriptors_and_frequencies/peptides_{int(identity * 100)}.csv\"\n",
    "            merge_df.to_csv(final_csv, index=False)\n",
    "            print(f\"✅ saved {final_csv}\")\n",
    "    \n",
    "    \n",
    "    df_without_cd_hit = df_limpio.merge(df_100, how='left' , on='SEQUENCE' )\n",
    "    path = f\"{CURATED_FOLDER}/descriptors_and_frequencies/peptides_without_cd_hit.csv\"\n",
    "    df_without_cd_hit.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d92e5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "prediccion_hemolitico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
